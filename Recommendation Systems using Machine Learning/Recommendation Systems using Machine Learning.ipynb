{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb8e90a",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/santoshd3/bank-customers/data?select=Churn+Modeling.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec25cde",
   "metadata": {},
   "source": [
    "# 1. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18d4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import pandas as pd  # Работа с данными\n",
    "import numpy as np  # Числовые операции\n",
    "import matplotlib.pyplot as plt  # Визуализация\n",
    "import seaborn as sns  # Красивые графики\n",
    "from sklearn.preprocessing import StandardScaler  # Нормализация данных\n",
    "from sklearn.cluster import KMeans  # Кластеризация\n",
    "from sklearn.decomposition import PCA  # Для визуализации кластеров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a865f5f8",
   "metadata": {},
   "source": [
    "# 2. Загрузка и просмотр данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e13c50",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bank_clients_data/bank_clients_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Загрузка данных (замени путь на свой, если файл локальный)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbank_clients_data/bank_clients_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Просмотр первых 5 строк\u001b[39;00m\n\u001b[1;32m      5\u001b[0m display(data\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bank_clients_data/bank_clients_data.csv'"
     ]
    }
   ],
   "source": [
    "# Загрузка данных (замени путь на свой, если файл локальный)\n",
    "data = pd.read_csv('bank_clients_data/bank_clients_data.csv')\n",
    "\n",
    "# Просмотр первых 5 строк\n",
    "display(data.head())\n",
    "\n",
    "# Основная информация о датасете\n",
    "print(data.info())\n",
    "\n",
    "# Проверка на пропущенные значения\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf45dd95",
   "metadata": {},
   "source": [
    "На основе данных можно сделать следующие выводы:\n",
    "\n",
    "1. **Объем данных**:  \n",
    "   Датсет содержит 10 000 записей (строк) и 14 столбцов. Это достаточно большой объем данных для анализа.\n",
    "\n",
    "\n",
    "2. **Отсутствие пропущенных значений**:  \n",
    "   В каждом столбце отсутствуют пропущенные значения (все столбцы имеют 10 000 непустых записей). Это упрощает предварительную обработку данных, так как не требуется заполнение или удаление пропусков.\n",
    "\n",
    "\n",
    "3. **Типы данных**:  \n",
    "   - **Числовые данные**: Большинство столбцов содержат числовые данные (`int64` и `float64`), такие как `CreditScore`, `Age`, `Balance`, `EstimatedSalary` и другие.  \n",
    "   - **Категориальные данные**: Есть три столбца с типом `object`, которые, скорее всего, содержат категориальные данные: `Surname`, `Geography`, и `Gender`. Эти данные могут потребовать преобразования в числовой формат (например, с помощью one-hot encoding) для использования в моделях машинного обучения.\n",
    "\n",
    "\n",
    "4. **Особенности данных**:  \n",
    "   - **CreditScore**: Кредитный рейтинг клиентов.  \n",
    "   - **Geography**: Клиенты представляют разные географические регионы (например, Франция, Испания).  \n",
    "   - **Gender**: В данных присутствуют клиенты обоих полов.  \n",
    "   - **Age**: Возраст клиентов.  \n",
    "   - **Balance**: Баланс на счетах клиентов.  \n",
    "   - **NumOfProducts**: Количество продуктов, используемых клиентами.  \n",
    "   - **HasCrCard**: Наличие кредитной карты.  \n",
    "   - **IsActiveMember**: Активность клиента.  \n",
    "   - **EstimatedSalary**: Оценка зарплаты клиентов.\n",
    "   - **Exited**: показатель ухода клиента из банка.  \n",
    "\n",
    "\n",
    "Данные выглядят чистыми и готовыми для дальнейшего анализа и построения моделей машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06487144",
   "metadata": {},
   "source": [
    "# 3. Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad736b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем ненужные столбцы (они не влияют на рекомендации)\n",
    "data.drop(['RowNumber', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "# Кодируем категориальные переменные (заменяем текст на числа)\n",
    "data = pd.get_dummies(data, columns=['Geography', 'Gender'], drop_first=True)\n",
    "\n",
    "# Нормализуем числовые признаки (чтобы KMeans работал корректно)\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(data)\n",
    "\n",
    "# Преобразуем обратно в DataFrame\n",
    "data_scaled = pd.DataFrame(scaled_features, columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ffd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data_scaled) # выводим таблицу с нормализированными данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2cbda",
   "metadata": {},
   "source": [
    "# 4. Поиск оптимального количества кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6171b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем количество кластеров с помощью метода локтя\n",
    "inertia = []\n",
    "K = range(1, 15) # Проверим от 1 до 15 кластеров\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(data_scaled)\n",
    "    inertia.append(kmeans.inertia_) # Записываем ошибку (inertia)\n",
    "\n",
    "# Визуализация метода локтя\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K, inertia)\n",
    "plt.xlabel('Количество кластеров')\n",
    "plt.ylabel('Inertia (ошибка)')\n",
    "plt.title('Метод локтя для выбора количества кластеров')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aca91c4",
   "metadata": {},
   "source": [
    "На графике видно, что после 4-го кластера ошибка уменьшается медленнее. Дальнейшее исследование будем проводить для 4-х кластеров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d767956",
   "metadata": {},
   "source": [
    "# 5. Кластеризация клиентов (KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем KMeans с 4 кластерами\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "data_scaled['Cluster'] = kmeans.fit_predict(data_scaled) # Добавляем номер кластера в данные\n",
    "\n",
    "# Смотрим, сколько клиентов в каждом кластере\n",
    "print(data_scaled['Cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3bcc1",
   "metadata": {},
   "source": [
    "**Кластеризация выполнена успешно**: алгоритм KMeans разделил данные на 5 кластеров.  \n",
    "**Распределение клиентов по кластерам** относительно равномерное, без сильного перекоса.  \n",
    "\n",
    "\n",
    "**Интерпретация**:  \n",
    "   - Кластеры могут представлять различные группы клиентов с похожими характеристиками (например, по возрасту, балансу, кредитному рейтингу и т.д.).  \n",
    "   - Для дальнейшего анализа можно исследовать средние значения признаков в каждом кластере, чтобы понять, чем отличаются группы клиентов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8f90f",
   "metadata": {},
   "source": [
    "# 6. Визуализация кластеров (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Снижаем размерность до 2D для визуализации\n",
    "pca = PCA(n_components=2)\n",
    "data_scaled['PCA1'] = pca.fit_transform(data_scaled)[:, 0]\n",
    "data_scaled['PCA2'] = pca.fit_transform(data_scaled)[:, 1]\n",
    "\n",
    "# Рисуем график кластеров\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=data_scaled, x='PCA1', y='PCA2', hue='Cluster', palette='viridis')\n",
    "plt.title('Визуализация кластеров клиентов')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44790b62",
   "metadata": {},
   "source": [
    "# 7. Оценка качества кластеризации\n",
    "Проверим, насколько хорошо KMeans разбил данные на кластеры. Используем:\n",
    "- Silhouette Score – показывает, насколько точки внутри кластера похожи друг на друга.\n",
    "- Davies-Bouldin Index – оценивает компактность и разделимость кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23dd26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# Вычисляем коэффициент силуэта\n",
    "silhouette = silhouette_score(data_scaled.drop(columns=['Cluster']), data_scaled['Cluster'])\n",
    "print(f'Silhouette Score (KMeans): {silhouette:.4f}')\n",
    "\n",
    "# Вычисляем индекс Дэвиса-Болдина\n",
    "db_index = davies_bouldin_score(data_scaled.drop(columns=['Cluster']), data_scaled['Cluster'])\n",
    "print(f'Davies-Bouldin Index (KMeans): {db_index:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee93112",
   "metadata": {},
   "source": [
    "Интерпретация метрик:\n",
    "\n",
    "- Silhouette Score: чем ближе к 1 – тем лучше (обычно 0.5+ хорошо).\n",
    "- Davies-Bouldin Index: чем меньше – тем лучше (оптимально <1).\n",
    "\n",
    "Silhouette Score 0.2343 – это довольно низкое значение, значит, точки внутри кластеров не очень похожи друг на друга.  \n",
    "Davies-Bouldin Index 1.5220 – тоже не идеальный (чем меньше, тем лучше), то есть кластеры не очень разделены.\n",
    "\n",
    "Это говорит о том, что KMeans не идеально работает с этим датасетом – возможно, кластеры не сферические, и KMeans их размывает.  \n",
    "Попробуем кластеризацию с **DBSCAN**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5eea63",
   "metadata": {},
   "source": [
    "# 8. Кластеризация с DBSCAN\n",
    "- DBSCAN хорош для данных, где кластеры имеют нечеткие границы.\n",
    "- Автоматически игнорирует выбросы, не относя их ни к одному кластеру.\n",
    "\n",
    "Параметры:\n",
    "- eps — максимальное расстояние между точками в одном кластере.\n",
    "- min_samples — минимальное количество точек, чтобы создать кластер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742988c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Подбираем значение eps с использованием K-дистанс\n",
    "neighbors = NearestNeighbors(n_neighbors=15)  # Используем min_samples = 15\n",
    "neighbors_fit = neighbors.fit(data_scaled.drop(columns=['Cluster', 'DBSCAN_Cluster']))\n",
    "distances, indices = neighbors_fit.kneighbors(data_scaled.drop(columns=['Cluster', 'DBSCAN_Cluster']))\n",
    "\n",
    "# Сортируем расстояния для построения графика\n",
    "distances = np.sort(distances[:, -1], axis=0)\n",
    "\n",
    "# Строим график K-дистанс\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(distances)\n",
    "plt.title('График K-дистанции для подбора eps')\n",
    "plt.xlabel('Точки')\n",
    "plt.ylabel('Расстояние до 4-й ближайшей точки')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f355af3",
   "metadata": {},
   "source": [
    "**Интерпретация графика:**  \n",
    "Выбор eps: ищем “плато” на графике, где расстояния резко возрастают. Это и будет хорошее значение для eps. На текущем графике эта точка равна 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Запускаем DBSCAN (eps расчитали с K-дистанс, min_samples подобрали)\n",
    "dbscan = DBSCAN(eps=3, min_samples=15)\n",
    "data_scaled['DBSCAN_Cluster'] = dbscan.fit_predict(data_scaled.drop(columns=['Cluster']))\n",
    "\n",
    "# Проверяем, сколько кластеров нашел DBSCAN\n",
    "print(data_scaled['DBSCAN_Cluster'].value_counts())\n",
    "\n",
    "# Визуализируем кластеры DBSCAN\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=data_scaled, x='PCA1', y='PCA2', hue='DBSCAN_Cluster', palette='viridis')\n",
    "plt.title('Кластеры DBSCAN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af538271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем Silhouette Score и Davies-Bouldin Index для DBSCAN\n",
    "if len(set(data_scaled['DBSCAN_Cluster'])) > 1:\n",
    "    silhouette_dbscan = silhouette_score(data_scaled.drop(columns=['Cluster', 'DBSCAN_Cluster']), data_scaled['DBSCAN_Cluster'])\n",
    "    print(f'Silhouette Score (DBSCAN): {silhouette_dbscan:.4f}')\n",
    "    \n",
    "    db_index_dbscan = davies_bouldin_score(data_scaled.drop(columns=['Cluster', 'DBSCAN_Cluster']), data_scaled['DBSCAN_Cluster'])\n",
    "    print(f'Davies-Bouldin Index (DBSCAN): {db_index_dbscan:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352abf9",
   "metadata": {},
   "source": [
    "Silhouette Score и Davies-Bouldin Index показывают, что DBSCAN плохо справляется с кластеризацией. Попробуем **GMM**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f25e34",
   "metadata": {},
   "source": [
    "# 9. Кластеризация с GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53adc622",
   "metadata": {},
   "source": [
    "GMM — это метод кластеризации, который предполагает, что данные могут быть сгенерированы с помощью смеси нескольких нормальных распределений. Это позволяет моделировать данные, которые могут не следовать простой форме, такой как круги или эллипсы, как в KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7f5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем нужную библиотеку\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8499d345",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m gmm \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Обучаем модель на данных, исключая уже имеющиеся столбцы с кластеризацией\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m gmm\u001b[38;5;241m.\u001b[39mfit(\u001b[43mdata_scaled\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCluster\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDBSCAN_Cluster\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Получаем метки кластеров\u001b[39;00m\n\u001b[1;32m      9\u001b[0m data_scaled[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGMM_Cluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m gmm\u001b[38;5;241m.\u001b[39mpredict(data_scaled\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCluster\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDBSCAN_Cluster\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Настроим и обучим модель GMM\n",
    "# n_components - количество кластеров\n",
    "gmm = GaussianMixture(n_components=4, random_state=42)\n",
    "\n",
    "# Обучаем модель на данных, исключая уже имеющиеся столбцы с кластеризацией\n",
    "gmm.fit(data_scaled.drop(columns=['Cluster', 'DBSCAN_Cluster']))\n",
    "\n",
    "# Получаем метки кластеров\n",
    "data_scaled['GMM_Cluster'] = gmm.predict(data_scaled.drop(columns=['Cluster', 'DBSCAN_Cluster']))\n",
    "\n",
    "# Посмотрим на количество записей в каждом кластере\n",
    "print(data_scaled['GMM_Cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a2ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec18cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c0cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ec2a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0124c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
