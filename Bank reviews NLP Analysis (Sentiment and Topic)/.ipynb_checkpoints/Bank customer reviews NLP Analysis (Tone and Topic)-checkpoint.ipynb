{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72dff5b",
   "metadata": {},
   "source": [
    "# Анализ отзывов клиентов банка (Тональность и Тематика)\n",
    "\n",
    "Описание проекта:\n",
    "Этот проект посвящен анализу тональности текстовых отзывов о банковских услугах.  \n",
    "**Цель проекта** — классифицировать отзывы как положительные или отрицательные, а также сегментировать основные темы отзывов. Для анализа использованы методы обработки естественного языка (NLP) и машинного обучения, включая классификацию текста и тематическое моделирование.\n",
    "\n",
    "Шаги выполнения проекта:\n",
    "\n",
    "# 1. Загрузка и подготовка данных\n",
    "\n",
    "Датасет: Determining the Sentiment of Bank Reviews Dataset, Kaggle\n",
    "https://www.kaggle.com/datasets/egorandreasyan/determining-the-sentiment-of-bank-reviews-dataset\n",
    "\n",
    "Этот датасет содержит текстовые отзывы клиентов банка с метками тональности (положительные/отрицательные).\n",
    "\n",
    "# 2. Предварительная обработка данных\n",
    "\n",
    " 2.1. Приведение текста к нижнему регистру.  \n",
    " 2.2. Удаление спецсимволов, цифр и лишних пробелов.  \n",
    " 2.3. Удаление стоп-слов для улучшения качества текста.  \n",
    "\n",
    "# 3. Преобразование текста в числовые данные\n",
    "\n",
    "Для преобразования текста в числовые векторы использовался метод TF-IDF (Term Frequency-Inverse Document Frequency), который позволяет оценить важность каждого слова в контексте документа.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# 4. Обучение модели машинного обучения\n",
    "\n",
    "Для классификации текста использован алгоритм Naive Bayes. Это один из классических методов для работы с текстовыми данными. Модель обучена на тренировочных данных, а затем оценена на тестовых.\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "**Предсказания**\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "**Оценка модели**\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 5. Самостоятельный анализ тональности\n",
    "\n",
    "\n",
    "\n",
    "# 6. Выделение ключевых тем (Topic Modeling)\n",
    "\n",
    "Для выделения ключевых тем можно использовать Latent Dirichlet Allocation (LDA) — популярную модель для тематического моделирования. Эта модель позволяет выявить скрытые темы в текстах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc3b77",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6c50d",
   "metadata": {},
   "source": [
    "# 1. Загрузка и подготовка данных\n",
    "Датасет: Determining the Sentiment of Bank Reviews Dataset, Kaggle https://www.kaggle.com/datasets/egorandreasyan/determining-the-sentiment-of-bank-reviews-dataset\n",
    "\n",
    "Этот датасет содержит текстовые отзывы клиентов банка с метками тональности (положительные/отрицательные)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c3ea654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>В Альфа-Банке работает замечательная девушка -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Оформляя рассрочку в м. Видео в меге тёплый ст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Очень порадовала оперативность работы в банке....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Имела неосторожность оформить потреб. кредит в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Небольшая предыстория: Нашел на сайте MDM банк...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx     Score                                               Text\n",
       "0    0  Positive  В Альфа-Банке работает замечательная девушка -...\n",
       "1    1  Negative  Оформляя рассрочку в м. Видео в меге тёплый ст...\n",
       "2    2  Positive  Очень порадовала оперативность работы в банке....\n",
       "3    3  Negative  Имела неосторожность оформить потреб. кредит в...\n",
       "4    4  Negative  Небольшая предыстория: Нашел на сайте MDM банк..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13999 entries, 0 to 13998\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   idx     13999 non-null  int64 \n",
      " 1   Score   13999 non-null  object\n",
      " 2   Text    13999 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 328.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "reviews = pd.read_csv('determining_the_sentiment_of_bank_reviews_dataset/train.csv', sep='\\t')\n",
    "reviews = pd.DataFrame(reviews)\n",
    "display(reviews.head())\n",
    "reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11ff25",
   "metadata": {},
   "source": [
    "# 2. Предварительная обработка данных\n",
    "2.1. Приведение текста к нижнему регистру.  \n",
    "2.2. Удаление спецсимволов, цифр и лишних пробелов.  \n",
    "2.3. Удаление стоп-слов для улучшения качества текста.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44858e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53d471bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hitwo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   idx     Score                                               Text\n",
      "0    0  Positive  В Альфа-Банке работает замечательная девушка -...\n",
      "1    1  Negative  Оформляя рассрочку в м. Видео в меге тёплый ст...\n",
      "2    2  Positive  Очень порадовала оперативность работы в банке....\n",
      "3    3  Negative  Имела неосторожность оформить потреб. кредит в...\n",
      "4    4  Negative  Небольшая предыстория: Нашел на сайте MDM банк...\n"
     ]
    }
   ],
   "source": [
    "# 1. Импорт библиотек и загрузка данных\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Загрузка стоп-слов для русского языка\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# Инициализация морфологического анализатора для лемматизации\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "# Просмотр первых строк\n",
    "print(reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "696a03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Функция очистки текста\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Очистка текста:\n",
    "    - Приведение к нижнему регистру\n",
    "    - Удаление спецсимволов, цифр, лишних пробелов\n",
    "    - Удаление стоп-слов\n",
    "    - Лемматизация\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):  # Проверка, что передан текст\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()  # Приводим к нижнему регистру\n",
    "    text = re.sub(r'[^а-яё\\s]', '', text)  # Удаляем все, кроме русских букв и пробелов\n",
    "    words = text.split()  # Разбиваем текст на слова\n",
    "    words = [morph.parse(word)[0].normal_form for word in words if word not in stop_words]  # Лемматизация и удаление стоп-слов\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb7ae264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swifter in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from swifter) (5.9.0)\n",
      "Requirement already satisfied: dask[dataframe]>=2.10.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from swifter) (2022.7.0)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from swifter) (4.64.1)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from swifter) (1.4.4)\n",
      "Requirement already satisfied: partd>=0.3.10 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (21.3)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2022.7.1)\n",
      "Requirement already satisfied: toolz>=0.8.2 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (0.11.2)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (6.0)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->swifter) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.8.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from tqdm>=4.33.0->swifter) (0.4.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from packaging>=20.0->dask[dataframe]>=2.10.0->swifter) (3.0.9)\n",
      "Requirement already satisfied: locket in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from partd>=0.3.10->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.0.0->swifter) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install swifter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86c02682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c53562a940245829c3ea12f70bc06c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/13999 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0  В Альфа-Банке работает замечательная девушка -...   \n",
      "1  Оформляя рассрочку в м. Видео в меге тёплый ст...   \n",
      "2  Очень порадовала оперативность работы в банке....   \n",
      "3  Имела неосторожность оформить потреб. кредит в...   \n",
      "4  Небольшая предыстория: Нашел на сайте MDM банк...   \n",
      "\n",
      "                                          clean_text  \n",
      "0  альфабанка работать замечательный девушка илья...  \n",
      "1  оформлять рассрочка м видео мег тёплый стан по...  \n",
      "2  очень порадовать оперативность работа банк зак...  \n",
      "3  иметь неосторожность оформить потреба кредит а...  \n",
      "4  небольшой предыстория найти сайт банк интересн...  \n"
     ]
    }
   ],
   "source": [
    "# 3. Применение очистки к данным\n",
    "import swifter # используем swifter для параллельного вычисления, иначе компьютер зависает\n",
    "reviews[\"clean_text\"] = reviews[\"Text\"].astype(str).swifter.apply(clean_text) \n",
    "\n",
    "# Просмотр результатов\n",
    "print(reviews[[\"Text\", \"clean_text\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "523d6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Сохранение очищенного датасета\n",
    "\n",
    "reviews.to_csv(\"cleaned_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffa3f7f",
   "metadata": {},
   "source": [
    "Результат:\n",
    "\n",
    " - Колонка clean_text содержит очищенные и лемматизированные отзывы.  \n",
    " - Теперь данные готовы для дальнейшего анализа, например, анализа тональности.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f68a71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>В Альфа-Банке работает замечательная девушка -...</td>\n",
       "      <td>альфабанка работать замечательный девушка илья...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Оформляя рассрочку в м. Видео в меге тёплый ст...</td>\n",
       "      <td>оформлять рассрочка м видео мег тёплый стан по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Очень порадовала оперативность работы в банке....</td>\n",
       "      <td>очень порадовать оперативность работа банк зак...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Имела неосторожность оформить потреб. кредит в...</td>\n",
       "      <td>иметь неосторожность оформить потреба кредит а...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Небольшая предыстория: Нашел на сайте MDM банк...</td>\n",
       "      <td>небольшой предыстория найти сайт банк интересн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx     Score                                               Text  \\\n",
       "0    0  Positive  В Альфа-Банке работает замечательная девушка -...   \n",
       "1    1  Negative  Оформляя рассрочку в м. Видео в меге тёплый ст...   \n",
       "2    2  Positive  Очень порадовала оперативность работы в банке....   \n",
       "3    3  Negative  Имела неосторожность оформить потреб. кредит в...   \n",
       "4    4  Negative  Небольшая предыстория: Нашел на сайте MDM банк...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  альфабанка работать замечательный девушка илья...  \n",
       "1  оформлять рассрочка м видео мег тёплый стан по...  \n",
       "2  очень порадовать оперативность работа банк зак...  \n",
       "3  иметь неосторожность оформить потреба кредит а...  \n",
       "4  небольшой предыстория найти сайт банк интересн...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Проверяем \n",
    "display(reviews.head())\n",
    "# Данные обработались корректно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c8151",
   "metadata": {},
   "source": [
    "# 3. Преобразование текста в числовые данные\n",
    "Преобразуем очищенный текст в числовые векторы с помощью TF-IDF (Term Frequency-Inverse Document Frequency). Это позволит модели машинного обучения понимать текст как набор значимых признаков.\n",
    "\n",
    "Выбрала TF-IDF, т.к. он прост в реалзиации и подходит для задачи. Ru-BERT занимает больше памяти.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8f2d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Импорт библиотеки\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3c827f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Преобразование текста в TF-IDF\n",
    "\n",
    "# Создаём объект TfidfVectorizer и применяем его к данным:\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words, max_features=5000)  # Указываем макс. число признаков\n",
    "tfidf_matrix = vectorizer.fit_transform(reviews[\"clean_text\"])  # Преобразуем текст в матрицу чисел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caf0e668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность матрицы: (13999, 5000)\n",
      "Примеры признаков (слов): ['аа' 'аба' 'абонент' 'абонентский' 'абсолют' 'абсолютбанк' 'абсолютно'\n",
      " 'абсолютный' 'абсурд' 'абэ']\n"
     ]
    }
   ],
   "source": [
    "# 3. Просмотр результатов\n",
    "\n",
    "#Чтобы убедиться, что всё работает, посмотрим на полученную матрицу:\n",
    "\n",
    "print(f\"Размерность матрицы: {tfidf_matrix.shape}\")  # Количество отзывов × количество признаков\n",
    "print(\"Примеры признаков (слов):\", vectorizer.get_feature_names_out()[:10])  # Выведем 10 самых частых слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296de412",
   "metadata": {},
   "source": [
    "# 4. Обучение модели машинного обучения  \n",
    "Мы будем использовать Naive Bayes (MultinomialNB), так как он хорошо подходит для задач классификации текста.  \n",
    "• 80% данных — для обучения.  \n",
    "• 20% данных — для тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "275c3053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество повторяющихся отзывов: 0\n"
     ]
    }
   ],
   "source": [
    "# проверка на дублирование\n",
    "print(f\"Количество повторяющихся отзывов: {reviews.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f764b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: (11199, 5000)\n",
      "Размер тестовой выборки: (2800, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разделение данных (20% - тест, 80% - обучение)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "tfidf_matrix, reviews[\"Score\"], test_size=0.2, random_state=42, shuffle=True\n",
    ") #shuffle=True (по умолчанию), чтобы данные перемешивались перед разделением\n",
    "\n",
    "# проверка размеров выборок\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "373c9366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Совпадающих текстов: 0\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем разреженные матрицы в плотные массивы\n",
    "X_train_dense = X_train.toarray()\n",
    "X_test_dense = X_test.toarray()\n",
    "\n",
    "# Сравниваем строки (тексты) в выборках\n",
    "common_texts = set(map(tuple, X_train_dense)).intersection(set(map(tuple, X_test_dense)))\n",
    "print(f\"Совпадающих текстов: {len(common_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a47751f",
   "metadata": {},
   "source": [
    "Выборки разлины по объему, совпадающих текстов и дублей нет, можем приступать в обучению модели и доверять её результатам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc8a6a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели: 0.92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.94      0.93      1401\n",
      "    Positive       0.94      0.90      0.92      1399\n",
      "\n",
      "    accuracy                           0.92      2800\n",
      "   macro avg       0.92      0.92      0.92      2800\n",
      "weighted avg       0.92      0.92      0.92      2800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Импорт модели Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Создаем и обучаем модель\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказания\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оцениваем точность модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Точность модели: {accuracy:.2f}\")\n",
    "\n",
    "# Выводим детальный отчет по метрикам\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7426ca6",
   "metadata": {},
   "source": [
    "Accuracy (Точность): модель правильно классифицирует 92% всех примеров. Качество модели хорошее.\n",
    "\n",
    "Precision (Точность для каждого класса):\n",
    "\n",
    "- Negative: 91% примеров, предсказанных как Negative, действительно являются Negative.\n",
    "\n",
    "- Positive: 94% примеров, предсказанных как Positive, действительно являются Positive.\n",
    "\n",
    "Recall (Полнота для каждого класса):\n",
    "\n",
    "- Negative: модель правильно идентифицирует 94% всех реальных Negative примеров.\n",
    "\n",
    "- Positive: модель правильно идентифицирует 90% всех реальных Positive примеров.\n",
    "\n",
    "F1-score (F1-мера):  \n",
    "Negative 0.93 и Positive 0.92 указывают на хороший баланс между precision и recall.\n",
    "\n",
    "Поддержка (Support): Количество примеров в каждом классе примерно одинаковое (1401 для Negative и 1399 для Positive), это говорит о сбалансированности данных.\n",
    "\n",
    "**Итог**: модель демонстрирует высокое качество классификации для обоих классов, с небольшим преимуществом в точности для класса Positive и в полноте для класса Negative. Общая точность модели (92%) и сбалансированные метрики F1-score указывают на то, что модель хорошо справляется с задачей классификации.\n",
    "\n",
    "Если бы точность модели была низкая, можно было попробовать альтернативные модели для классификации:\n",
    "- Logistic Regression — часто работает лучше, но медленнее.\n",
    "- Random Forest — хуже для текстов, но стоило бы проверить.\n",
    "- ruBERT — мощная нейросеть, но требует больше вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3181f83",
   "metadata": {},
   "source": [
    "Поскольку ранее мы проверяли утечку данных в тестовую выборку, отсутствие дублей и совпадающих текстов, можем доверять высокой точности модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083665e2",
   "metadata": {},
   "source": [
    "# 5. Самостоятельный анализ тональности  \n",
    "Мы уже подготовили данные и лемматизировали текст, так что теперь можем провести анализ тональности для каждого отзыва.  \n",
    "TextBlob — хороший инструмент для анализа тональности для русского языка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1c3529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fca2bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  sentiment_polarity  \\\n",
      "0  В Альфа-Банке работает замечательная девушка -...            0.000000   \n",
      "1  Оформляя рассрочку в м. Видео в меге тёплый ст...            0.000000   \n",
      "2  Очень порадовала оперативность работы в банке....            0.166667   \n",
      "3  Имела неосторожность оформить потреб. кредит в...            0.000000   \n",
      "4  Небольшая предыстория: Нашел на сайте MDM банк...            0.000000   \n",
      "\n",
      "  sentiment_label  \n",
      "0        positive  \n",
      "1        positive  \n",
      "2        positive  \n",
      "3        positive  \n",
      "4        positive  \n"
     ]
    }
   ],
   "source": [
    "# Функция для анализа тональности\n",
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text) # Тональность будет на шкале от -1 (отрицательная) до 1 (положительная)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    return sentiment\n",
    "\n",
    "# Применяем функцию для анализа тональности к каждому отзыву\n",
    "reviews['sentiment_polarity'] = reviews['Text'].apply(analyze_sentiment)\n",
    "\n",
    "# Классификация: положительный, отрицательный\n",
    "reviews['sentiment_label'] = reviews['sentiment_polarity'].apply(\n",
    "lambda x: 'positive' if x >= 0 else 'negative'\n",
    ")\n",
    "\n",
    "# Выводим результаты\n",
    "print(reviews[['Text', 'sentiment_polarity', 'sentiment_label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "627dba1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Sentiment Analysis: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Сравниваем результаты с метками из датасета (точность)\n",
    "accuracy = (reviews['sentiment_label'] == reviews['Score']).mean()\n",
    "print(f'Accuracy of Sentiment Analysis: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "514d40f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deeppavlov in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: nltk<3.10.0,>=3.2.4 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (3.9.1)\n",
      "Requirement already satisfied: numpy<1.24 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (1.21.5)\n",
      "Requirement already satisfied: filelock<3.10.0,>=3.0.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (3.6.0)\n",
      "Requirement already satisfied: fastapi<=0.89.1,>=0.47.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (0.89.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.19.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (2.28.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (0.37.1)\n",
      "Requirement already satisfied: scipy==1.10.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (1.10.0)\n",
      "Requirement already satisfied: prometheus-client<=1.16.0,>=0.13.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (0.14.1)\n",
      "Requirement already satisfied: pandas<1.6.0,>=1.0.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (1.4.4)\n",
      "Requirement already satisfied: tqdm<4.65.0,>=4.42.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (4.64.1)\n",
      "Requirement already satisfied: pydantic<2 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (1.10.21)\n",
      "Requirement already satisfied: pybind11==2.10.3 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (2.10.3)\n",
      "Requirement already satisfied: scikit-learn<1.1.0,>=0.24 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (1.0.2)\n",
      "Requirement already satisfied: uvicorn<0.19.0,>=0.13.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov) (0.18.3)\n",
      "Requirement already satisfied: starlette==0.22.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from fastapi<=0.89.1,>=0.47.0->deeppavlov) (0.22.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (4.12.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from nltk<3.10.0,>=3.2.4->deeppavlov) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from nltk<3.10.0,>=3.2.4->deeppavlov) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from nltk<3.10.0,>=3.2.4->deeppavlov) (8.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from pandas<1.6.0,>=1.0.0->deeppavlov) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from pandas<1.6.0,>=1.0.0->deeppavlov) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.19.0->deeppavlov) (2022.9.14)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from scikit-learn<1.1.0,>=0.24->deeppavlov) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from tqdm<4.65.0,>=4.42.0->deeppavlov) (0.4.5)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from uvicorn<0.19.0,>=0.13.0->deeppavlov) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<1.6.0,>=1.0.0->deeppavlov) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov) (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deeppavlov[aio] in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: scipy==1.10.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (1.10.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.19.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (2.28.1)\n",
      "Requirement already satisfied: pydantic<2 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (1.10.21)\n",
      "Requirement already satisfied: scikit-learn<1.1.0,>=0.24 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (1.0.2)\n",
      "Requirement already satisfied: uvicorn<0.19.0,>=0.13.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (0.18.3)\n",
      "Requirement already satisfied: wheel in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (0.37.1)\n",
      "Requirement already satisfied: nltk<3.10.0,>=3.2.4 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (3.9.1)\n",
      "Requirement already satisfied: prometheus-client<=1.16.0,>=0.13.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (0.14.1)\n",
      "Requirement already satisfied: tqdm<4.65.0,>=4.42.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (4.64.1)\n",
      "Requirement already satisfied: pybind11==2.10.3 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (2.10.3)\n",
      "Requirement already satisfied: filelock<3.10.0,>=3.0.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (3.6.0)\n",
      "Requirement already satisfied: numpy<1.24 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (1.21.5)\n",
      "Requirement already satisfied: fastapi<=0.89.1,>=0.47.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (0.89.1)\n",
      "Requirement already satisfied: pandas<1.6.0,>=1.0.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from deeppavlov[aio]) (1.4.4)\n",
      "Requirement already satisfied: starlette==0.22.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from fastapi<=0.89.1,>=0.47.0->deeppavlov[aio]) (0.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov[aio]) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov[aio]) (3.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from nltk<3.10.0,>=3.2.4->deeppavlov[aio]) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from nltk<3.10.0,>=3.2.4->deeppavlov[aio]) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from nltk<3.10.0,>=3.2.4->deeppavlov[aio]) (8.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from pandas<1.6.0,>=1.0.0->deeppavlov[aio]) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from pandas<1.6.0,>=1.0.0->deeppavlov[aio]) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.19.0->deeppavlov[aio]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.19.0->deeppavlov[aio]) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.19.0->deeppavlov[aio]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.19.0->deeppavlov[aio]) (2022.9.14)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from scikit-learn<1.1.0,>=0.24->deeppavlov[aio]) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from tqdm<4.65.0,>=4.42.0->deeppavlov[aio]) (0.4.5)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from uvicorn<0.19.0,>=0.13.0->deeppavlov[aio]) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<1.6.0,>=1.0.0->deeppavlov[aio]) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from anyio<5,>=3.4.0->starlette==0.22.0->fastapi<=0.89.1,>=0.47.0->deeppavlov[aio]) (1.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: deeppavlov 1.7.0 does not provide the extra 'aio'\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# пробуем другую модель\n",
    "\n",
    "!pip install deeppavlov\n",
    "!pip install deeppavlov[aio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0e114fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from torch) (2022.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hitwo\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\hitwo\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34aacbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\deeppavlov\\__main__.py\", line 2, in <module>\n",
      "    from .deep import main\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\deeppavlov\\deep.py\", line 20, in <module>\n",
      "    from deeppavlov.core.common.cross_validation import calc_cv_score\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\deeppavlov\\core\\common\\cross_validation.py\", line 21, in <module>\n",
      "    from sklearn.model_selection import KFold\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py\", line 82, in <module>\n",
      "    from .base import clone\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 17, in <module>\n",
      "    from .utils import _IS_32BIT\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 21, in <module>\n",
      "    from scipy.sparse import issparse\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\scipy\\sparse\\__init__.py\", line 283, in <module>\n",
      "    from . import csgraph\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csgraph\\__init__.py\", line 185, in <module>\n",
      "    from ._laplacian import laplacian\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\scipy\\sparse\\csgraph\\_laplacian.py\", line 7, in <module>\n",
      "    from scipy.sparse.linalg import LinearOperator\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py\", line 120, in <module>\n",
      "    from ._isolve import *\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\_isolve\\__init__.py\", line 4, in <module>\n",
      "    from .iterative import *\n",
      "  File \"C:\\Users\\hitwo\\anaconda3\\lib\\site-packages\\scipy\\sparse\\linalg\\_isolve\\iterative.py\", line 9, in <module>\n",
      "    from . import _iterative\n",
      "ImportError: DLL load failed while importing _iterative: Не найден указанный модуль.\n"
     ]
    }
   ],
   "source": [
    "!python -m deeppavlov install sentiment_twitter_ru  # Устанавливаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cfd1d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 12:50:06.803 INFO in 'deeppavlov.download'['download'] at line 138: Skipped http://files.deeppavlov.ai/v1/classifiers/rusentiment_convers_bert/rusentiment_convers_bert_torch.tar.gz download because of matching hashes\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19060\\746822665.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Загружаем готовую модель для анализа тональности\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msentiment_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrusentiment_convers_bert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Функция для анализа тональности\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\deeppavlov\\core\\commands\\infer.py\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(config, mode, load_trained, install, download)\u001b[0m\n\u001b[0;32m     53\u001b[0m                             .format(component_config.get('class_name', component_config.get('ref', 'UNKNOWN'))))\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mcomponent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrom_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'id'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomponent_config\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\deeppavlov\\core\\common\\params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[1;34m(params, mode, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\deeppavlov\\core\\common\\registry.py\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mConfigError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model {} is not registered.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls_from_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcls_from_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_REGISTRY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\deeppavlov\\core\\common\\registry.py\u001b[0m in \u001b[0;36mcls_from_str\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     40\u001b[0m                           .format(name))\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\deeppavlov\\models\\preprocessors\\torch_transformers_preprocessor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputFeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from deeppavlov import build_model, configs\n",
    "\n",
    "# Загружаем готовую модель для анализа тональности\n",
    "sentiment_model = build_model(configs.classifiers.rusentiment_convers_bert, download=True)\n",
    "\n",
    "# Функция для анализа тональности\n",
    "def analyze_sentiment(text):\n",
    "    return sentiment_model([text])[0]  # Берем первый элемент из предсказания\n",
    "\n",
    "# Применяем к данным\n",
    "reviews['predicted_sentiment'] = reviews['Text'].apply(analyze_sentiment)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = (reviews['predicted_sentiment'] == reviews['Score']).mean()\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053fe69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5874f0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30797a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28e39bc9",
   "metadata": {},
   "source": [
    "# 6. Выделение ключевых тем (Topic Modeling) с использованием LDA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
